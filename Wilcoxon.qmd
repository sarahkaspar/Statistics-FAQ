---
title: "The Wilcoxon test"
format: html
---


The Wilcoxon, or Mann-Whitney U test, is a non-parametric independence test that is used to compare two groups. 

We can apply it on data that consists of two groups, $X$ and $Y$, for example a "control" and a "treatment" group, where in both we measure the same biological indicator of some effect. 

## Why non-parametric tests?

In the example below, you see data from an experiment where the effect of different conditions on plant growth was investigated. 
```{r message=FALSE, warning=FALSE}
library(tidyverse)
myplants <- PlantGrowth %>% filter(group %in%  c("ctrl", "trt1"))

myplants %>% 
  ggplot(aes(x=group, y = weight))+
  geom_jitter(width=0.07)
```
Here, the groups $X$ and $Y$ correspond to "ctrl" and "trt", and we want to find out whether the weight is different between them. In an example like this, we would typically use a **t-test**, which calculates the mean and variance of both groups and checks for a difference in means. This comparison of means assumes that the data are somewhat well described by the two group means, meaning that in each group, the data points are roughly centered around their mean, and have no huge outliers. The t-test is a **parametric** test, because it makes assumptions about the distribution of the data (such as outlined above) and estimates parameters, namely mean and standard deviation, which describe a normal distribution.

Below, you see another example, where the t-test is not advised. In the `coin::rotarod` data set, rats were assigned to two different treatment groups, and of each rat the time it managed to blanace on a rotating cylinder (without falling off) was measured. 


```{r}
library(coin)

library(ggbeeswarm)
rotarod %>% 
  ggplot(aes(x=group, y = time))+
  geom_beeswarm()
```
The experiment stopped at 300 s. As you see in the data above, all of the rats in the control group made it to the end without falling, whereas in the treatment group, 5 rats dropped out earlier. This data is not well described by group means and standard deviation, for several reasons: 

- the data are censored, i.e. cut off at 300s, and therefore also skewed.
- No standard deviation can be determined for the control group, because all rats have the same time.

For this data, a Wilcoxon test is a better choice, because it is **non-parametric**, i.e. it does not try to fit a distribution to the data. Instead, it transforms the data into ranks, as we will see below. 

## Assumptions, null and alternative hypothesis

Even though no specific distribution is assumed when applying the Wilcoxon test, some assumptions are still made (see [Wikipedia](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test):

1. All the observations from both groups are independent of each other,
2. The responses are at least ordinal (i.e., one can at least say, of any two observations, which is the greater),
3. Under the null hypothesis $H_0$, the distributions of both populations are identical.

If you don't know what "independence" means in the statistics context, have a look [here](https://sarahkaspar.github.io/biostatistics-course/01-sampling.html).

To approach the difference between groups without calculating for example a mean, the null hypothesis is described as follows.

$$H_0: P(X > Y) = P(Y > X)$$ 

In words: If taking any to measurements $x_i$ and $x_j$ from $X$ and $Y$, the chance of $x_i$ being greater than $y_i$ is the same as vice versa. 

The alternative hypothesis is that this probability is not the same:
$$H_A: P(X > Y) = P(Y > X)$$ 

An intuitive **interpretation** is therefore that the test detects differences in median. 

## Rank transformation

If we are investigating the probability of $Y>X$, the exact numbers of the data points in $X$ and $Y$ do not matter. For example, if $x_i = 2$ and $y_j=2.2$, then $x_i<y_j$. But if $y_j = 200$ instead, then we still have $x_i<y_j$. It's only about the order of the data points.

The order of data points can be encoded as **ranks**. For the Wilcoxon test, we rank all the data (ignoring the groups). This means we give rank 1 to the lowest value, rank 2 to the second lowest, and so on. 
Let's look at the ranks for a subset of the plants data.

We create a subset:

```{r}
plants_subset <- myplants[c(1:5,11:15),]
plants_subset
```
Now we assign ranks:
```{r}
plants_subset <- plants_subset %>% mutate(rank=rank(weight))
plants_subset %>% arrange(rank)
```

You can see that the `rank` columns contains the values from 1 to 10 - or almost. The values 2 and 3 are missing, because there is a *tie*: The measurement $4.17$ (the second lowest) appears twice. Therefore, both measurements get rank $2.5$. 

## The U statistic

A test statistic is a value that gets extreme (extremely large or extremely small) in case there is a difference between the two group - or, in other words: in case there is evidence for a deviation from the null hypothesis. 

A simple approach to compare the two groups is to sum up the ranks within each group and compare them. We can do this for our example:

```{r}
plants_subset %>% 
  group_by(group) %>% 
  summarize(rank_sum = sum(rank))
```

This tells us that the control group has a lower rank sum, i.e. on average the ranks in the control group are smaller. 
The next thing we need to find out is how unlikely it is to see a difference in rank sums like this by chance, if in reality $X$ and $Y$ come from the same distribution. 

**Intuitively**, we can compare the observed rank sums to what we expect in a few extreme cases. For example: 

- If the control group had *all* the lower ranks we would see rank sum $R_x = 1+2+3+4+5 = 15$ for `ctrl` and $R_y = 6+7+8+9+10 = 40$ for `trt1`. (And vice versa.)
- If the ranks were completely evenly distributed among the two groups, we'd see the same rank sum, $R_x=R_y=55$, in both groups. 

Our example seems to be somewhat in the middle. 

**In the test**, we use the **Mann-Whitney U statistic**, of which we know the distribution (behavior) under the null hypothesis. It is defined as 

$$U = min(U_x, U_y)$$ with

$$U_x = n_xn_y + \frac{n_x(n_x + 1)}{2} - R_x $$ and
$$U_y = n_xn_y + \frac{n_y(n_y + 1)}{2} - R_y $$.

Let's dissect this. 

$R_x$ and $R_y$ are the rank sums that we already calculated for our example. 
In the $U_x$, the rank sum $R_x$ gets subtracted from the term 
$$n_xn_y + \frac{n_x(n_x + 1)}{2}$$
This is the rank sum that we'd expect in case $X$ had all the upper ranks. That expected rank sum depends on $n_x$ and $n_y$, the number of data points in $X$ and $Y$, respectively. We calculated it by hand for the example above, and this calculation can be abstracted to the term you see here. 

Since 
$$U_x = \text{expectation if X has all the upper ranks} - R_x$$,
$U_x$ will be 

- 0 if $Y$ in fact *has* all the upper ranks,
- close to 0 if $X$ has mostly upper ranks, and 
- $\gg0$ if $X$ has intermediate or lower ranks. 

The same logic applies for $U_y$. By taking the minimum of $U_x$ and $U_y$, we will have 

- a $U$ that is low / close to 0 if either $X$ or $Y$ have mostly upper ranks and 
- high otherwise. 

In summary, a low $U$ represents evidence for $X$ and $Y$ being different, represented as a difference in rank sums. 

## From U statistic to p-value

Per definition, the p-value is the probability of seeing data (i.e. a test statistic) at least as extreme as what as actually observed, under the assumption that the null hypothesis is true. 

If the probability of our data under the null hypothesis is small (usually: $p<0.05$), we reject the null hypothesis and report a significant difference between the two groups. 

For calculating $p$, we need knowledge how the test statistic behaves under the null hypothesis, specifically we need to know its **null distribution**. 

There are different ways of getting to this distribution and thus the p-value, which will lead to small differences in the resulting p-value. Two examples are:

- Combinatorics: The null hypothesis says that the two groups come from the same distribution and thus the probability of $P(X>Y) = P(Y>X)$. All ranks therefore have the same chance for all the data points. One can thus spell out all combinations of ranks and data points and calculate the corresponding $U$ for getting the null distribution. The p-value is the percentage of possible $U$s that are smaller or equal to the observed one. (In practice, one doesn't spell out all possibilities, but combinatorics allows to calculate $p$ directly.)
- For larger sample sizes ($n>20$), the distribution of $U$ can be approximated by a normal distribution. 

If you use the R implementation of the `wilcox.test`, the documentation reads:
> By default (if exact is not specified), an exact p-value is computed if the samples contain less than 50 finite values and there are no ties. Otherwise, a normal approximation is used.

You are usually fine with sticking to the default. You may see slightly different results from different packages due to small differences in their defaults. Again, in most cases, these don't impact the conclusion. If they do, it's time to further investigate which method fits your data best.

## Running the test in R

Applying the built-in test to the example subset gives:
```{r}
wilcox.test(weight ~ group, data = plants_subset)
```
**Advanced**: There is another implementation of the Wilcoxon test in the `coin` package, which allows more flexibility in calculating the test statistic and null distribution, and allows stratifying the test among blocking factors. 
Example for usage:

```{r}
coin::wilcox_test(weight ~ group, data = plants_subset, distribution="approximate")
```

We can also run the test for the whole `plantGrowth` and `rotarod` data sets:
```{r}
wilcox.test(time ~ group, rotarod)
```
```{r}
wilcox.test(weight ~ group, myplants)
```
## Comparison to t-test

For the same data sets the t-test will give the following results:
```{r}
t.test(weight ~ group, myplants)
```
The t-test gives a comparable result for the `plantGrowth` data set, coming to the same conclusion that the difference in weights is not significant between `ctrl` and `trt1`. In most casese where the t-test can be used, it's also OK to use the Wilcoxon test. 
One caveat is that in the Wilcoxon test, we drop all the information on the actual values of the data points. This, in combination with making less assumptions on the data, can sometimes make it harder to detect a significant deviation of the data from the our null assumption. This is especially relevant for small data sets. We say that the **t-test has a higher power than the Wilcoxon test**, meaning that if there is a difference between the groups, the t-test is often better in detecting it. 

The limitations of the rank-based test become clear when we look at very small data sets. Consider two groups with only 3 data points each. There are only 20 ways to distribute 6 ranks among 2 groups.

```{r}
choose(6,3)
```

A two-sided p-value will therefore never be below $\frac{1}{20}\cdot 2$. 
To demonstrate:
```{r}
x <- 1:3 # x has all the lower ranks
y <- 4:6 # y has all the upper ranks
wilcox.test(x,y)
```

## What other methods to consider if your data are not normal

The Wilcoxon test is usually used when the data are not normally distributed, so a t-test doesn't apply. However, there are also other approaches that might apply: 

- The data might follow another known distribution around the group means, such as Poisson, or binomial. In this case, you can have a look at Poisson ANOVA or Fisher test.
- The data might fulfill the normality criterion after a transformation. A common one is the log-transformation.


